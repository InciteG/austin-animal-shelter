{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#data manipulation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.option_context('display.max_rows', None, 'display.max_columns', None)\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "#stats/ml\n",
    "import scipy\n",
    "import sklearn as sk\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import auc\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from imblearn.over_sampling import RandomOverSampler,SMOTE, ADASYN\n",
    "from imblearn.under_sampling import RandomUnderSampler,TomekLinks, EditedNearestNeighbours\n",
    "\n",
    "#vis\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('seaborn')\n",
    "\n",
    "#additional support packages\n",
    "from datetime import date, datetime, timedelta\n",
    "import random\n",
    "import re\n",
    "import joblib #save models\n",
    "import shap #feature importance explainability\n",
    "\n",
    "# import logging #create and update logger files\n",
    "# logging.basicConfig(filename='..\\models\\logs\\performance.log',)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelTrainer():\n",
    "    '''Class for training models for Austin Animal Center data\n",
    "    \n",
    "    Inputs\n",
    "    ===========\n",
    "    model: str\n",
    "        chooses model to load. Only accepts \"log\" and \"xgb\" as inputs for Logistic and XGBClassifier respectively.\n",
    "    \n",
    "    test_size: float (0.0 to 1.0)\n",
    "        size of testing split for data\n",
    "    \n",
    "    resample: boolean\n",
    "        defines whether to use resampling or not\n",
    "    \n",
    "    resample_weight: list/array\n",
    "        must be 2 integer values. Default is [20,20]. \n",
    "        First element pertains to oversample weighting. \n",
    "        Second element pertains to undersample weighting.\n",
    "    \n",
    "    Attributes\n",
    "    ===========\n",
    "    \n",
    "    self.model_id: str\n",
    "        'log' or 'xgb' for model to train\n",
    "    \n",
    "    self._resample: str\n",
    "        store resample input repr function\n",
    "    \n",
    "    self._resample_weight: list/array\n",
    "        store resample_weight input repr function\n",
    "    \n",
    "    self._test_size: float\n",
    "        store test_size input for repr function\n",
    "    \n",
    "    self.data: dataframe\n",
    "        loaded dataset \n",
    "    \n",
    "    self.id: panda Series Object\n",
    "        store ID column from dataset\n",
    "    \n",
    "    self.dv: panda Series object\n",
    "        target variable column\n",
    "    \n",
    "    self.iv: panda Series object\n",
    "        target variable column\n",
    "    \n",
    "    self.xtrain: dataframe\n",
    "        independent variables for training\n",
    "    \n",
    "    self.xtest: dataframe\n",
    "        independent variables for testing\n",
    "    \n",
    "    self.ytrain: panda Series object\n",
    "        dependent variables for training\n",
    "    \n",
    "    self.ytest: panda Series object\n",
    "        dependent variables for testing\n",
    "    \n",
    "    self.model: \n",
    "        initialized model object\n",
    "    \n",
    "    self.log: dataframe\n",
    "        dataframe housing historical model performance data\n",
    "    \n",
    "    self.fi: dataframe\n",
    "        dataframe housing historical feature importance data\n",
    "    \n",
    "    self.name: str\n",
    "        naming convention for currently loaded model\n",
    "    \n",
    "    self.precision: float\n",
    "        precision of current model\n",
    "    \n",
    "    self.precision: float\n",
    "        precision of current model\n",
    "    \n",
    "    self.recall: float\n",
    "        recall of current model\n",
    "    \n",
    "    self.f1score: float\n",
    "        f1 of current model\n",
    "    \n",
    "    self.threshold: float\n",
    "        optimized threshold value\n",
    "    \n",
    "    self.pr_auc: float\n",
    "        area under curve for Precision-Recall curve\n",
    "    \n",
    "    self.precision: float\n",
    "        precision of current model\n",
    "    \n",
    "    self.precision_array: list/array\n",
    "        precision array for Precision-Recall curve\n",
    "    \n",
    "    self.recall_array: list/array\n",
    "        recall array for Precision-Recall curve\n",
    "    \n",
    "    self.feature_importance: dataframe\n",
    "        feature importance of loaded model\n",
    "    \n",
    "    self.shap: list/array\n",
    "        Array of SHAP values - can be used to plot SHAP related graphs outside of class.\n",
    "    \n",
    "    \n",
    "    Methods\n",
    "    ===========\n",
    "    \n",
    "    get_model:\n",
    "        retrieves specified model from sklearn or xgb packages\n",
    "        \n",
    "    get_data:\n",
    "        load dataset\n",
    "    \n",
    "    get_log:\n",
    "        load historical log\n",
    "        \n",
    "    get_fi_table:\n",
    "        load feature importance table\n",
    "        \n",
    "    base_run:\n",
    "        run model fitting. Runs evaluate_model and return_feature_importance\n",
    "        \n",
    "    optimize_run(grid): \n",
    "        runs hyperparameter optimization, input is a dictionary for the parameters to tune\n",
    "        \n",
    "    resample:\n",
    "        apply resampling to dataset\n",
    "    \n",
    "    evaluate_model:\n",
    "        populates precision, recall, f1 and pr_auc variables. \n",
    "    \n",
    "    return_feature_importance:\n",
    "        get feature importance and shap values\n",
    "        \n",
    "    self.plot_precision_recall_curve:\n",
    "        plot PR curve\n",
    "    \n",
    "    self.plot_feature_importance:\n",
    "        plot feature importance\n",
    "        \n",
    "    self.save_model(name):\n",
    "        save model to path. Only takes name\n",
    "    self.load_model(name):\n",
    "        load saved model from name. Path already specified in function\n",
    "    \n",
    "    \n",
    "    '''\n",
    "    def __init__(self, model='log',test_size=.2,over_samp=None,under_samp=None,over_weight=.2,under_weight=.3):\n",
    "        self.check_condition(model,['log','xgb'],\"'model' input not correctly defined. Value must be 'log' or 'xgb'\")\n",
    "        self.check_condition(over_samp,[None, 'random','smote'],\"'over_samp' input not correctly defined. Value must be None, random or smote\")\n",
    "        self.check_condition(under_samp,[None, 'random','tomek','enn'],\"'under_samp' input not correctly defined. Value must be None, random or tomek or enn\")\n",
    "\n",
    "        \n",
    "        self.model_id = model\n",
    "        self.name=self.model_id\n",
    "        \n",
    "        #private variables\n",
    "        self._over_samp=over_samp\n",
    "        self._under_samp=under_samp\n",
    "        self._over_weight=over_weight\n",
    "        self._under_weight=under_weight\n",
    "        \n",
    "        self._test_size=test_size\n",
    "        \n",
    "        self.data = self.get_data()\n",
    "        \n",
    "        self.dv=self.data['Time at Center']\n",
    "        self.id=self.data['Pet ID']\n",
    "        self.iv=self.data.drop(['Pet ID','Time at Center'],axis=1).copy()\n",
    "        \n",
    "        #set training, testing \n",
    "        \n",
    "        self.xtrain, self.xtest, self.ytrain, self.ytest = train_test_split(self.iv, \n",
    "                                                self.dv, \n",
    "                                                test_size=test_size, \n",
    "                                                random_state=0,stratify=self.dv) \n",
    "        if over_samp==None:\n",
    "            pass\n",
    "        else:\n",
    "            self.resample()\n",
    "            self.name=self.name+over_samp+str(over_weight)+under_samp+str(under_weight)\n",
    "        \n",
    "        self.model = self.get_model()\n",
    "        self.log = self.get_log()\n",
    "        self.fi= self.get_fi_table()\n",
    "        \n",
    "        self.precision='Model not evaluated yet'\n",
    "        self.recall='Model not evaluated yet'\n",
    "        self.f1score='Model not evaluated yet'\n",
    "        self.threshold ='Model not evaluated yet'\n",
    "        self.pr_auc = 'Model not evaluated yet'\n",
    "        self.roc_auc = 'Model not evaluated yet'\n",
    "        self.precision_array = 'Model not evaluated yet'\n",
    "        self.recall_array = 'Model not evaluated yet'\n",
    "        \n",
    "        self.fpr='Model not evaluated yet'\n",
    "        self.tpr='Model not evaluated yet'\n",
    "        self.fpr_array='Model not evaluated yet'\n",
    "        self.tpr_array='Model not evaluated yet'\n",
    "        self.threshold_roc = 'Model not evaluated yet'\n",
    "        self.gmean = 'Model not evaluated yet'\n",
    "        self.feature_importance='Model not evaluated yet'\n",
    "        self.shap='SHAP values not defined'\n",
    "        \n",
    "    def __repr__(self):\n",
    "        return f\"ModelTrainer(model={self.model_id},test_size={self._test_size},resample={self._resample},self.resample_weight={self._resample_weight})\"\n",
    "    \n",
    "    \n",
    "    ''' Methods to grab essentials\n",
    "    =================================================================================================================='''\n",
    "    def get_model(self):\n",
    "        if self.model_id =='log':\n",
    "            model = LogisticRegression()\n",
    "        elif self.model_id=='xgb':\n",
    "            model=xgb.XGBClassifier()\n",
    "        return model\n",
    "\n",
    "    def get_data(self):\n",
    "        data=pd.read_csv(r'..\\data\\feature_final.csv')\n",
    "        cat =['Outcome Type', 'Intake Type', 'Intake Condition',\n",
    "       'Pet Type', 'MixBreed','BaseBreed', 'MixColor', 'BaseColor', 'NS_intake', 'NS_clinic',\n",
    "       'City', 'Gender', 'FirstLetterName', 'NameLengthBin',]\n",
    "        data=pd.get_dummies(data,drop_first=True,columns=cat) #one hot encode categorical variables\n",
    "        return data\n",
    "    \n",
    "    def get_log(self):\n",
    "        try:\n",
    "            log = pd.read_csv(r'..\\data\\log.csv')\n",
    "        except:\n",
    "            log=pd.DataFrame(columns=['Name','ModelType','F1','PR-AUC','G-mean','ROC-AUC','PRThreshold','ROCThreshold','LogTime'])\n",
    "        return log\n",
    "    \n",
    "    def get_fi_table(self):\n",
    "        try:\n",
    "            fi = pd.read_csv(r'..\\data\\fi.csv')\n",
    "        except:\n",
    "            fi=pd.DataFrame(columns=['ModelName','Feature','Importance'])\n",
    "        return fi\n",
    "    \n",
    "    ''' Methods to run models\n",
    "    =================================================================================================================='''\n",
    "    \n",
    "    #base run \n",
    "    def base_run(self):        \n",
    "        self.model.fit(self.xtrain,self.ytrain) #train\n",
    "        \n",
    "        name = self.name\n",
    "        #evaluate model \n",
    "        self.evaluate_model()\n",
    "        self.return_feature_importance()\n",
    "        \n",
    "        #only save model and update log if outperforms \n",
    "        log_class = self.log.loc[self.log.ModelType==self.model_id]\n",
    "        name=name+str(log_class.shape[0])\n",
    "        if log_class.shape[0]==0:\n",
    "            f1max = 0\n",
    "        else:\n",
    "            f1max = log_class.F1.max()\n",
    "        if self.f1score>f1max:\n",
    "            log_update=[[name,self.model_id,self.f1score,self.pr_auc,self.gmean,self.roc_auc,self.threshold,self.threshold_roc,datetime.now()]]\n",
    "            log_update_df = pd.DataFrame(data=log_update,columns=['Name','ModelType','F1','PR-AUC','G-mean','ROC-AUC','PRThreshold','ROCThreshold','LogTime'])\n",
    "            self.log=self.log.append(log_update_df)\n",
    "\n",
    "            self.feature_importance['ModelName']=name\n",
    "            self.fi=self.fi.append(self.feature_importance)\n",
    "            self.save_log_fi()\n",
    "\n",
    "            self.save_model(name)\n",
    "        else:\n",
    "            pass\n",
    "        \n",
    "    def optimize_run(self, grid):\n",
    "        cv = StratifiedKFold(n_splits=5)\n",
    "        grid_search = RandomizedSearchCV(estimator=self.model, param_distributions=grid, n_jobs=-1, \n",
    "                               cv=cv, scoring='f1',error_score=0,random_state=0)\n",
    "        grid_result = grid_search.fit(self.xtrain,self.ytrain)\n",
    "        # summarize results\n",
    "        print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "        self.model=grid_result.best_estimator_\n",
    "        \n",
    "        self.name = 'CV_'+self.name\n",
    "        \n",
    "        self.base_run()\n",
    "        \n",
    "    \n",
    "    ''' Methods to evaluate models\n",
    "    =================================================================================================================='''\n",
    "    def return_feature_importance(self):\n",
    "        fi_df = pd.DataFrame(data=self.iv.columns.values,columns=['Feature'])\n",
    "        # get importance\n",
    "        \n",
    "        if self.model_id=='log':\n",
    "            importance = self.model.coef_[0]\n",
    "            metric = 'Coefficient'\n",
    "        elif self.model_id=='xgb':\n",
    "            importance = self.model.feature_importances_\n",
    "            metric='Gain'\n",
    "            explainer = shap.TreeExplainer(self.model)\n",
    "            self.shap = explainer.shap_values(self.xtest)\n",
    "            mean_shap = [np.mean([abs(i[x]) for i in self.shap]) for x in range(len(self.shap[0]))]\n",
    "            fi_df['SHAP']=mean_shap\n",
    "\n",
    "        fi_df['Importance']=importance\n",
    "        self.feature_importance=fi_df\n",
    "        print('feature_importance attribute updated')\n",
    "       \n",
    "        \n",
    "    #optional choice - base option oversample by 20% and undersample by 20%\n",
    "    def resample(self):\n",
    "        #random over, random under\n",
    "        if (self._over_samp=='random') &(self._under_samp=='random'):\n",
    "            over = RandomOverSampler(sampling_strategy=self._over_weight)\n",
    "            self.xtrain, self.ytrain = over.fit_resample(self.xtrain,self.ytrain)\n",
    "            under = RandomUnderSampler(sampling_strategy=self._under_weight)\n",
    "            self.xtrain, self.ytrain = under.fit_resample(self.xtrain, self.ytrain)\n",
    "            print(self.ytrain.value_counts())\n",
    "        elif (self._over_samp=='smote') &(self._under_samp=='random'):\n",
    "            over = SMOTE(sampling_strategy=self._over_weight)\n",
    "            self.xtrain, self.ytrain = over.fit_resample(self.xtrain,self.ytrain)\n",
    "            under = RandomUnderSampler(sampling_strategy=self._under_weight)\n",
    "            self.xtrain, self.ytrain = under.fit_resample(self.xtrain, self.ytrain)\n",
    "            print(self.ytrain.value_counts())\n",
    "        elif (self._over_samp=='smote') &(self._under_samp=='tomek'):\n",
    "            over = SMOTE(sampling_strategy=self._over_weight)\n",
    "            self.xtrain, self.ytrain = over.fit_resample(self.xtrain,self.ytrain)\n",
    "            under = TomekLinks(sampling_strategy='majority',n_jobs=-1)\n",
    "            self.xtrain, self.ytrain = under.fit_resample(self.xtrain, self.ytrain)\n",
    "            print(self.ytrain.value_counts())\n",
    "        elif (self._over_samp=='smote') &(self._under_samp=='enn'):\n",
    "            over = SMOTE(sampling_strategy=self._over_weight)\n",
    "            self.xtrain, self.ytrain = over.fit_resample(self.xtrain,self.ytrain)\n",
    "            under = EditedNearestNeighbours(sampling_strategy='majority',n_jobs=-1)\n",
    "            self.xtrain, self.ytrain = under.fit_resample(self.xtrain, self.ytrain)\n",
    "            print(self.ytrain.value_counts())\n",
    "        #smote, random under\n",
    "        #smote, tomek links\n",
    "        #smote, edit nearest neighbors\n",
    "        \n",
    "        return\n",
    "\n",
    "    #return y_pred, precision, recall, f1, precision-recall curve\n",
    "    def evaluate_model(self):\n",
    "        ypred = self.model.predict_proba(self.xtest)\n",
    "        yhat = ypred[:, 1]\n",
    "        \n",
    "        precision, recall, thresholds = precision_recall_curve(self.ytest, yhat)\n",
    "        self.precision_array = precision\n",
    "        self.recall_array = recall\n",
    "        # convert to f score\n",
    "        f1score = (2 * precision * recall) / (precision + recall)\n",
    "        # locate the index of the largest f score\n",
    "        ix = np.argmax(f1score)\n",
    "        print('Best Threshold=%f, F-Score=%.3f' % (thresholds[ix], f1score[ix]))\n",
    "        self.pr_auc = auc(recall,precision)\n",
    "        self.precision=precision[ix]\n",
    "        self.recall=recall[ix]\n",
    "        self.threshold=thresholds[ix]\n",
    "        self.f1score=f1score[ix]\n",
    "        print('precision, recall, threshold, f1score attributes updated')\n",
    "        \n",
    "        self.fpr_array, self.tpr_array, thresholds_roc = roc_curve(self.ytest,yhat)\n",
    "        self.roc_auc = roc_auc_score(self.ytest,yhat)\n",
    "        \n",
    "        gmeans = np.sqrt(self.tpr_array * (1-self.fpr_array))\n",
    "        ix = np.argmax(gmeans)\n",
    "        print('Best Threshold=%f, G-Mean=%.3f' % (thresholds_roc[ix], gmeans[ix]))\n",
    "        self.fpr=self.fpr_array[ix]\n",
    "        self.tpr=self.tpr_array[ix]\n",
    "        self.threshold_roc=thresholds_roc[ix]\n",
    "        self.gmean=gmeans[ix]\n",
    "        print('tpr, fpr, gmean attributes updated')\n",
    "        \n",
    "    ''' Methods to plot \n",
    "    =================================================================================================================='''   \n",
    "        \n",
    "    def plot_precision_recall_curve(self):\n",
    "        '''plot precision recall curve and optimal threshold'''\n",
    "        plt.plot(self.recall_array,self.precision_array, marker='.', label='Model')\n",
    "        plt.scatter(self.recall, self.precision, marker='o', color='black', label='Best')\n",
    "        # axis labels\n",
    "        plt.xlabel('Recall')\n",
    "        plt.ylabel('Precision')\n",
    "        plt.legend()\n",
    "        # show the plot\n",
    "        plt.show()\n",
    "        \n",
    "    def plot_feature_importance(self,top=10,bottom=10):\n",
    "        fi_tab = self.feature_importance.copy().sort_values(by='Importance',ascending=True)\n",
    "        plot_fidf =fi_tab.head(top).append(fi_tab.tail(bottom))\n",
    "        plot_fidf.plot.barh('Feature','Importance',figsize=(12,8))\n",
    "        plt.show()\n",
    "        \n",
    "    def plot_roc_curve(self):\n",
    "        plt.plot(self.fpr_array,self.tpr_array, marker='.', label='Model')\n",
    "        plt.scatter(self.fpr, self.tpr, marker='o', color='black', label='Best')\n",
    "        # axis labels\n",
    "        plt.xlabel('False Positive Rate')\n",
    "        plt.ylabel('True Positive Rate')\n",
    "        plt.legend()\n",
    "        # show the plot\n",
    "        plt.show()\n",
    "    \n",
    "    ''' Methods to save and log\n",
    "    =================================================================================================================='''\n",
    "    \n",
    "    def save_model(self,name):\n",
    "        path = r'..\\\\models\\\\'+name+'.pkl'\n",
    "        joblib.dump(self.model, path)\n",
    "    \n",
    "    def load_model(self,name):\n",
    "        path = r'..\\\\models\\\\'+name+'.pkl'\n",
    "        self.model=joblib.load(path)\n",
    "        self.base_run()\n",
    "        return\n",
    "    \n",
    "    def save_log_fi(self):\n",
    "        self.log.to_csv(r'..\\data\\log.csv',index=False)\n",
    "        self.fi.to_csv(r'..\\data\\fi.csv',index=False)\n",
    "        \n",
    "    ''' Static methods only to be run within class as assigned, not called\n",
    "    =================================================================================================================='''\n",
    "    \n",
    "\n",
    "    \n",
    "    @staticmethod\n",
    "    def check_condition(var, values,msg):\n",
    "        if var not in values:\n",
    "            raise Exception(msg)\n",
    "        else:\n",
    "            pass\n",
    "        \n",
    "if __name__ == '__main__':\n",
    "    return"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
